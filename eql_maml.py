"""Trains the deep symbolic regression architecture on given functions to produce a simple equation that describes
the dataset."""

import pickle
import numpy as np
import os
import torch
import torch.nn as nn
import torch.optim as optim
from utils import pretty_print, functions
from utils.symbolic_network import SymbolicNetL0
from utils.regularization import L12Smooth  #, l12_smooth
from inspect import signature
import time
import argparse
import json

from feynman_ai_equations import equation_dict
from benchmark import *

class Benchmark(BaseBenchmark):
    """Benchmark object just holds the results directory (results_dir) to save to and the hyper-parameters. So it is
    assumed all the results in results_dir share the same hyper-parameters. This is useful for benchmarking multiple
    functions with the same hyper-parameters."""

    def __init__(self, results_dir, n_layers=2, reg_weight=5e-3, learning_rate=1e-2,
                 n_epochs1=10001, n_epochs2=10001, x_dim=1):
        """try to learn multiple functions within the same experiment
        for now assume they all take the same number of input variables
        additional arg x_dim
        """
        super().__init__(results_dir, n_layers, reg_weight, learning_rate, n_epochs1, n_epochs2)
        # meta-learning stuff: shared net and
        self.x_dim = x_dim
        width = len(self.activation_funcs)
        n_double = functions.count_double(self.activation_funcs)
        self.net = SymbolicNetL0(self.n_layers, in_dim=1, funcs=self.activation_funcs,
                              initial_weights=[
                                  # kind of a hack for truncated normal
                                  torch.fmod(torch.normal(0, init_sd_first, size=(x_dim, width + n_double)), 2),
                                  torch.fmod(torch.normal(0, init_sd_middle, size=(width, width + n_double)), 2),
                                  torch.fmod(torch.normal(0, init_sd_middle, size=(width, width + n_double)), 2),
                                  torch.fmod(torch.normal(0, init_sd_last, size=(width, 1)), 2)
                              ])

    def meta_learn(self, func_names, trials):
        """Meta-train the EQL network on data generated by the given functions.
        Arguments:
            func_names: list of strings that describes the functions
            trials: number of trials to train from scratch. Will save the results for each trial.
        """
        #TODO 1)outer loop 2)bookkeping

        for func_name in func_names:
            print ("Adapt to function {}".format(func_name))
            func = equation_dict[func_name]
            assert self.x_dim == len(signature(func).parameters)
            self.adapt(func, func_name)


    def adapt(self, func, func_name=''):
        """adapt the network to find a given function"""

        x, y = generate_data(func, N_TRAIN)
        x_test, y_test = generate_data(func, N_TEST, range_min=DOMAIN_TEST[0], range_max=DOMAIN_TEST[1])



if __name__ == "__main__":

    parser = argparse.ArgumentParser(description="Train the EQL network.")
    parser.add_argument("--results-dir", type=str, default='results/benchmark/test')
    parser.add_argument("--n-layers", type=int, default=2, help="Number of hidden layers, L")
    parser.add_argument("--reg-weight", type=float, default=5e-3, help='Regularization weight, lambda')
    parser.add_argument('--learning-rate', type=float, default=1e-2, help='Base learning rate for training')
    parser.add_argument("--n-epochs1", type=int, default=10001, help="Number of epochs to train the first stage")
    parser.add_argument("--n-epochs2", type=int, default=10001,
                        help="Number of epochs to train the second stage, after freezing weights.")

    args = parser.parse_args()
    kwargs = vars(args)
    print(kwargs)

    if not os.path.exists(kwargs['results_dir']):
        os.makedirs(kwargs['results_dir'])
    meta = open(os.path.join(kwargs['results_dir'], 'args.txt'), 'a')
    meta.write(json.dumps(kwargs))
    meta.close()

    bench = Benchmark(**kwargs)

    func_names = ["id", "exp1"]
    bench.meta_learn(func_names=func_names, trials=10)
