"""Trains the deep symbolic regression architecture on given functions to produce a simple equation that describes
the dataset."""

import pickle
import numpy as np
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import grad
from utils import pretty_print, functions
from utils.symbolic_network import SymbolicNetL0, SymbolicNet
from utils.regularization import L12Smooth  #, l12_smooth
from utils.l2l import *
from inspect import signature
import time
import argparse
import json

from feynman_ai_equations import equation_dict
from benchmark import *

N_SUPPORT, N_QUERY = 10, 10

class Benchmark(BaseBenchmark):
    """Benchmark object just holds the results directory (results_dir) to save to and the hyper-parameters. So it is
    assumed all the results in results_dir share the same hyper-parameters. This is useful for benchmarking multiple
    functions with the same hyper-parameters."""

    def __init__(self, results_dir, n_layers=2, reg_weight=5e-3, learning_rate=1e-2,
                 n_epochs1=10001, n_epochs2=10001, x_dim=1):
        """try to learn multiple functions within the same experiment
        for now assume they all take the same number of input variables
        additional arg x_dim
        """
        super().__init__(results_dir, n_layers, reg_weight, learning_rate, n_epochs1, n_epochs2)
        # meta-learning stuff: shared net and
        self.x_dim = x_dim
        width = len(self.activation_funcs)
        n_double = functions.count_double(self.activation_funcs)
        self.net = SymbolicNet(self.n_layers,
                              funcs=self.activation_funcs,
                              initial_weights=[
                                  # kind of a hack for truncated normal
                                  torch.fmod(torch.normal(0, init_sd_first, size=(x_dim, width + n_double)), 2),
                                  torch.fmod(torch.normal(0, init_sd_middle, size=(width, width + n_double)), 2),
                                  torch.fmod(torch.normal(0, init_sd_middle, size=(width, width + n_double)), 2),
                                  torch.fmod(torch.normal(0, init_sd_last, size=(width, 1)), 2)
                              ])
        self.meta_lr = self.learning_rate

    def meta_learn(self, func_names, trials):
        """Meta-train the EQL network on data generated by the given functions.
        Arguments:
            func_names: list of strings that describes the functions
            trials: number of trials to train from scratch. Will save the results for each trial.
        """
        opt = optim.Adam(self.net.parameters(), self.meta_lr)
        iterations = 10000

        equations = dict()
        train_losses = dict()
        for func_name in func_names:
            equations[func_name] = []
            train_losses[func_name] = []
        for counter in range(iterations):
            verbose = (counter + 1) % 250 == 0
            opt.zero_grad()
            eval_loss = 0
            for func_name in func_names:
                print ("Adapt to function {}".format(func_name))
                func = equation_dict[func_name]
                assert self.x_dim == len(signature(func).parameters)
                # adapt to func
                eql_for_func = self.adapt(func, func_name)
                # eval task performance
                x, y = generate_data(func, N_QUERY)
                inputs, labels = x, y
                eval_loss += self.get_loss(eql_for_func, inputs, labels)
            eval_loss.backward()
            # Average the accumulated gradients and optimize
            for p in self.net.parameters():
                p.grad.data.mul_(1.0 / len(func_names))
            opt.step()

    def get_loss(self, model, inputs, labels):
        # MSE loss
        criterion = nn.MSELoss()
        outputs = model(inputs)
        mse_loss = criterion(outputs, labels)
        # norm 1/2 reg
        regularization = L12Smooth()
        reg_loss = regularization(model.get_weights_tensor())
        loss = mse_loss + self.reg_weight * reg_loss
        return loss

    def adapt(self, func, func_name=''):
        """adapt the network to find a given function"""

        x, y = generate_data(func, N_SUPPORT)
        inputs, labels = x, y

        # clone module and specify adaptation params
        learner = clone_module(self.net)
        diff_params = [p for p in learner.parameters() if p.requires_grad]
        loss = self.get_loss(learner, inputs, labels)

        first_order = False; allow_unused = False; allow_nograd = False; second_order=True#these should probably be command-line arguments
        # -------------------------------------------------------------------------------begin learn2learn excerpt to compute gradients
        if allow_nograd:
            # Compute relevant gradients
            diff_params = [p for p in learner.parameters() if p.requires_grad]
            grad_params = grad(loss,
                               diff_params,
                               retain_graph=second_order,
                               create_graph=second_order,
                               allow_unused=allow_unused)
            gradients = []
            grad_counter = 0

            # Handles gradients for non-differentiable parameters
            for param in learner.parameters():
                if param.requires_grad:
                    gradient = grad_params[grad_counter]
                    grad_counter += 1
                else:
                    gradient = None
                gradients.append(gradient)
        else:
            try:
                gradients = grad(loss,
                                 learner.parameters(),
                                 retain_graph=second_order,
                                 create_graph=second_order,
                                 allow_unused=allow_unused)
            except RuntimeError:
                traceback.print_exc()
                print('learn2learn: Maybe try with allow_nograd=True and/or allow_unused=True ?')

        # Update the module
        adapted_learner = self.maml_update(learner, self.learning_rate, gradients)
        # -------------------------------------------------------------------------------end learn2learn excerpt
        return adapted_learner

    def maml_update(self, model, lr, grads=None):
        """
        [[Source]](https://github.com/learnables/learn2learn/blob/master/learn2learn/algorithms/maml.py)
        **Description**
        Performs a MAML update on model using grads and lr.
        The function re-routes the Python object, thus avoiding in-place
        operations.
        NOTE: The model itself is updated in-place (no deepcopy), but the
              parameters' tensors are not.
        **Arguments**
        * **model** (Module) - The model to update.
        * **lr** (float) - The learning rate used to update the model.
        * **grads** (list, *optional*, default=None) - A list of gradients for each parameter
            of the model. If None, will use the gradients in .grad attributes.
        **Example**
        ~~~python
        maml = l2l.algorithms.MAML(Model(), lr=0.1)
        model = maml.clone() # The next two lines essentially implement model.adapt(loss)
        grads = autograd.grad(loss, model.parameters(), create_graph=True)
        maml_update(model, lr=0.1, grads)
        ~~~
        """
        if grads is not None:
            params = list(model.parameters())
            if not len(grads) == len(list(params)):
                msg = 'WARNING:maml_update(): Parameters and gradients have different length. ('
                msg += str(len(params)) + ' vs ' + str(len(grads)) + ')'
                print(msg)
            for p, g in zip(params, grads):
                if g is not None:
                    p.update = - lr * g
        return update_module(model)

if __name__ == "__main__":

    parser = argparse.ArgumentParser(description="Train the EQL network.")
    parser.add_argument("--results-dir", type=str, default='results/benchmark/test')
    parser.add_argument("--n-layers", type=int, default=2, help="Number of hidden layers, L")
    parser.add_argument("--reg-weight", type=float, default=5e-3, help='Regularization weight, lambda')
    parser.add_argument('--learning-rate', type=float, default=1e-2, help='Base learning rate for training')
    parser.add_argument("--n-epochs1", type=int, default=10001, help="Number of epochs to train the first stage")
    parser.add_argument("--n-epochs2", type=int, default=10001,
                        help="Number of epochs to train the second stage, after freezing weights.")

    args = parser.parse_args()
    kwargs = vars(args)
    print(kwargs)

    if not os.path.exists(kwargs['results_dir']):
        os.makedirs(kwargs['results_dir'])
    meta = open(os.path.join(kwargs['results_dir'], 'args.txt'), 'a')
    meta.write(json.dumps(kwargs))
    meta.close()

    bench = Benchmark(**kwargs)

    func_names = ["id", "exp1"]
    bench.meta_learn(func_names=func_names, trials=10)
